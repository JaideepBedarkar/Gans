{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####DATA_LOADING######\n",
    "trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = datasets.MNIST(root='./data', train=True, transform=trans, download=False)\n",
    "test_set = datasets.MNIST(root='./data', train=False, transform=trans, download=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4,shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GENERATOR###\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.noise_to_3d = nn.Linear(100,7*7*256)\n",
    "        self.block = nn.Sequential(nn.ConvTranspose2d(256,128,kernel_size =3 ,stride=3 ,padding=0),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.ConvTranspose2d(128,1,kernel_size =8 ,stride=1 ,padding=0),\n",
    "                                  nn.BatchNorm2d(1), \n",
    "                                  nn.Tanh())\n",
    "    def forward(self,z):\n",
    "        out = self.noise_to_3d(z)\n",
    "        out = out.reshape(out.size(0),256,7,7)\n",
    "        out = self.block(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####DISCRIMINATOR####\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer1 = nn.Sequential(\n",
    "                                  nn.Conv2d(1,16,kernel_size =7 ,stride=1 ,padding=3),\n",
    "                                  nn.BatchNorm2d(16),\n",
    "                                  nn.LeakyReLU(negative_slope=0.2),\n",
    "                                  nn.MaxPool2d(kernel_size = 2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                                  nn.Conv2d(16,32,kernel_size =5 ,stride=1 ,padding=2),\n",
    "                                  nn.BatchNorm2d(32),\n",
    "                                  nn.LeakyReLU(negative_slope=0.2),\n",
    "                                  nn.MaxPool2d(kernel_size =2 , stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*32,1)\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow((np.transpose(npimg, (1, 2, 0))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = torch.randn(size,100)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator()\n",
    "gen = gen.cuda()\n",
    "dis = discriminator()\n",
    "dis = dis.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion  = nn.BCELoss()\n",
    "optimizer_generator = optim.Adam(gen.parameters(),lr = 0.0002,betas=(0.5,0.999))\n",
    "optimizer_discriminator = optim.Adam(dis.parameters(),lr = 0.0002,betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ TRAINING ######################\n",
    "for epoch in range(1):\n",
    "    running_total_discriminator_loss  = 0.0\n",
    "    running_generator_loss = 0.0\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        input_img,l = data\n",
    "        input_img,l = input_img.cuda(),l.cuda()\n",
    "        #zero the parameter gradients\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        optimizer_generator.zero_grad()\n",
    "        #forward + loss + backprop#\n",
    "        \n",
    "        ###Training discriminator###\n",
    "    \n",
    "        real_out = dis(input_img)\n",
    "        real_loss = criterion(real_out,torch.ones(real_out.shape).cuda())\n",
    "        Noise = noise(4).cuda()\n",
    "        fake_image = gen(Noise)\n",
    "        fake_out = dis(fake_image)\n",
    "        fake_dis_loss = criterion(fake_out,torch.zeros(fake_out.shape).cuda())\n",
    "        \n",
    "        total_discriminator_loss = real_loss + fake_dis_loss\n",
    "        total_discriminator_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "       \n",
    "        ###Training generator###\n",
    "        Noise = noise(4).cuda()\n",
    "        fake_image = gen(Noise)\n",
    "        fake_out = dis(fake_image)\n",
    "        generator_loss = criterion(fake_out,torch.ones(fake_out.shape).cuda())\n",
    "        \n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "        \n",
    "         # print statistics\n",
    "        running_total_discriminator_loss += total_discriminator_loss.item()\n",
    "        running_generator_loss += generator_loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] dis_loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_total_discriminator_loss / 2000))\n",
    "            print('[%d, %5d] gen_loss: %.3f' %\n",
    "                  (epoch + 1, i + 1,running_generator_loss  / 2000))\n",
    "            running_total_discriminator_loss  = 0.0\n",
    "            running_generator_loss = 0.0\n",
    "    \n",
    "    fake_image = gen(torch.randn(1,100).cuda())\n",
    "    output = fake_image.cpu()\n",
    "    imshow(torchvision.utils.make_grid(output))\n",
    "    #plt.savefig(str(epoch)+\".pdf\")\n",
    "    #fake_image = gen(torch.randn(1,100).cuda())    \n",
    "    #cv2.imwrite(os.path.join('./trained_output', '%05d.png'), get_image(fake_image[0]))\n",
    "torch.save(dis.state_dict(), 'dis.pth')\n",
    "torch.save(gen.state_dict(), 'gen.pth')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1568, out_features=1, bias=True)\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# Evaluation ####################\n",
    "\n",
    "####### Loading Model #######\n",
    "gen_eval = generator()\n",
    "gen_eval = gen_eval.cuda()\n",
    "dis_eval = discriminator()\n",
    "dis_eval = dis_eval.cuda()\n",
    "gen_eval.load_state_dict(torch.load('gen.pth'))\n",
    "dis_eval.load_state_dict(torch.load('dis.pth'))\n",
    "gen_eval.eval()\n",
    "dis_eval.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Generating Image ###############\n",
    "fake_image = gen_eval(torch.randn(1,100).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = fake_image.cpu()\n",
    "imshow(torchvision.utils.make_grid(output))\n",
    "#plt.savefig(str(epoch)+\".pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
